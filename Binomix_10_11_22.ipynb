{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Binomix/binomix.github.io/blob/master/Binomix_10_11_22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AnnotateVCF"
      ],
      "metadata": {
        "id": "-os2zy1SPhhW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsVYu0PtOxDZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import gzip\n",
        "import argparse\n",
        "\n",
        "def CheckFileExist(fn):\n",
        "    if not os.path.isfile(fn):\n",
        "        return None\n",
        "    return os.path.abspath(fn)\n",
        "\n",
        "\n",
        "def AnnotateVCF( args ):\n",
        "    vcf_fn = args.vcf_fn\n",
        "    b_fn = args.b_fn\n",
        "    annovcf_fn = args.annovcf_fn\n",
        "\n",
        "    if vcf_fn == None or CheckFileExist(vcf_fn) == None:\n",
        "        print >> sys.stderr, \"Missing VCF input\"; sys.exit(1)\n",
        "    if b_fn == None or CheckFileExist(skyhawk_fn) == None:\n",
        "        print >> sys.stderr, \"Missing input\"; sys.exit(1)\n",
        "    if annovcf_fn == None:\n",
        "        print >> sys.stderr, \"Missing VCF output filename\"; sys.exit(1)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    with gzip.open(b_fn, \"rb\") if b_fn.endswith(\".gz\") else open(b_fn, \"r\") as f:\n",
        "        for row in f:\n",
        "            col = row.split()\n",
        "            results[col[2] + \"-\" + col[3]] = row[0]\n",
        "\n",
        "    with gzip.open(vcf_fn, \"rb\") if vcf_fn.endswith(\".gz\") else open(vcf_fn, \"r\") as f, open(annovcf_fn, \"w\") as o:\n",
        "        for row in f:\n",
        "            row = row.rstrip(\"\\n\")\n",
        "            col = row.split()\n",
        "            if col[0] == \"#CHROM\":\n",
        "                print >> o, '##FILTER=<ID=b,Description=\"filtered\">'\n",
        "                print >> o, row\n",
        "            elif col[0][0] == col[0][1] and col[0][0] == \"#\":\n",
        "                print >> o, row\n",
        "            else:\n",
        "                stat = results[col[0] + \"-\" + col[1]]\n",
        "                if stat == \"X\" or stat == \"S\":\n",
        "                    col[6] = \"b\"\n",
        "                else:\n",
        "                    col[6] = \"PASS\"\n",
        "                print >> o, \"\\t\".join(col)\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(\n",
        "            description=\"Annotate an VCF according output\" )\n",
        "\n",
        "    parser.add_argument('--vcf_fn', type=str, default=None,\n",
        "            help=\"Unannotated VCF file input, mandatory\")\n",
        "\n",
        "    parser.add_argument('--skyhawk_fn', type=str, default=None,\n",
        "            help=\"Decision input, mandatory\")\n",
        "\n",
        "    parser.add_argument('--annovcf_fn', type=str, default=None,\n",
        "            help=\"Annotated VCF file output, mandatory\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if len(sys.argv[1:]) == 0:\n",
        "        parser.print_help()\n",
        "        sys.exit(1)\n",
        "\n",
        "    AnnotateVCF( args )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nucleus(*tensorflow*)"
      ],
      "metadata": {
        "id": "OLl223OuPq7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import selu\n",
        "import param\n",
        "\n",
        "class Bin(object):\n",
        "\n",
        "    def __init__(self, inputShape = (2*param.flankingBaseNum+1, 4, param.matrixNum),\n",
        "                       outputShape1 = (4, ), outputShape2 = (2, ), outputShape3 = (4, ), outputShape4 = (6, ),\n",
        "                       kernelSize1 = (1, 4), kernelSize2 = (2, 4), kernelSize3 = (3, 4),\n",
        "                       pollSize1 = (5, 1), pollSize2 = (4, 1), pollSize3 = (3, 1),\n",
        "                       numFeature1 = 16, numFeature2 = 32, numFeature3 = 48,\n",
        "                       hiddenLayerUnits4 = 336, hiddenLayerUnits5 = 168,\n",
        "                       initialLearningRate = param.initialLearningRate, learningRateDecay = param.learningRateDecay,\n",
        "                       dropoutRateFC4 = param.dropoutRateFC4, dropoutRateFC5 = param.dropoutRateFC5,\n",
        "                       l2RegularizationLambda = param.l2RegularizationLambda, l2RegularizationLambdaDecay = param.l2RegularizationLambdaDecay):\n",
        "        self.inputShape = inputShape\n",
        "        self.outputShape1 = outputShape1; self.outputShape2 = outputShape2; self.outputShape3 = outputShape3; self.outputShape4 = outputShape4\n",
        "        self.kernelSize1 = kernelSize1; self.kernelSize2 = kernelSize2; self.kernelSize3 = kernelSize3\n",
        "        self.pollSize1 = pollSize1; self.pollSize2 = pollSize2; self.pollSize3 = pollSize3\n",
        "        self.numFeature1 = numFeature1; self.numFeature2 = numFeature2; self.numFeature3 = numFeature3\n",
        "        self.hiddenLayerUnits4 = hiddenLayerUnits4; self.hiddenLayerUnits5 = hiddenLayerUnits5\n",
        "        self.learningRateVal = initialLearningRate; self.learningRateDecay = learningRateDecay\n",
        "        self.dropoutRateFC4Val = dropoutRateFC4; self.dropoutRateFC5Val = dropoutRateFC5\n",
        "        self.l2RegularizationLambdaVal = l2RegularizationLambda; self.l2RegularizationLambdaDecay = l2RegularizationLambdaDecay\n",
        "        self.trainLossRTVal = None; self.trainSummaryRTVal = None; self.getLossLossRTVal = None\n",
        "        self.predictBaseRTVal = None; self.predictZygosityRTVal = None; self.predictVarTypeRTVal = None; self.predictIndelLengthRTVal = None\n",
        "        self.g = tf.Graph()\n",
        "        self._buildGraph()\n",
        "        self.session = tf.Session(graph = self.g, config=tf.ConfigProto(intra_op_parallelism_threads=param.NUM_THREADS))\n",
        "\n",
        "    def _buildGraph(self):\n",
        "        with self.g.as_default():\n",
        "            XPH = tf.placeholder(tf.float32, [None, self.inputShape[0], self.inputShape[1], self.inputShape[2]], name='XPH')\n",
        "            self.XPH = XPH\n",
        "\n",
        "            YPH = tf.placeholder(tf.float32, [None, self.outputShape1[0] + self.outputShape2[0] + self.outputShape3[0] + self.outputShape4[0]], name='YPH')\n",
        "            self.YPH = YPH\n",
        "\n",
        "            learningRatePH = tf.placeholder(tf.float32, shape=[], name='learningRatePH')\n",
        "            self.learningRatePH = learningRatePH\n",
        "\n",
        "            phasePH = tf.placeholder(tf.bool, shape=[], name='phasePH')\n",
        "            self.phasePH = phasePH\n",
        "\n",
        "            dropoutRateFC4PH = tf.placeholder(tf.float32, shape=[], name='dropoutRateFC4PH')\n",
        "            self.dropoutRateFC4PH = dropoutRateFC4PH\n",
        "\n",
        "            dropoutRateFC5PH = tf.placeholder(tf.float32, shape=[], name='dropoutRateFC5PH')\n",
        "            self.dropoutRateFC5PH = dropoutRateFC5PH\n",
        "\n",
        "            l2RegularizationLambdaPH = tf.placeholder(tf.float32, shape=[], name='dropoutRateFC5PH')\n",
        "            self.l2RegularizationLambdaPH = l2RegularizationLambdaPH\n",
        "\n",
        "            conv1 = tf.layers.conv2d(inputs=XPH,\n",
        "                                     filters=self.numFeature1,\n",
        "                                     kernel_size=self.kernelSize1,\n",
        "                                     kernel_initializer = tf.contrib.layers.variance_scaling_initializer(factor=2.0, mode='FAN_IN', uniform=False),\n",
        "                                     padding=\"same\",\n",
        "                                     activation=selu.selu,\n",
        "                                     name='conv1')\n",
        "            self.conv1 = conv1\n",
        "\n",
        "            pool1 = tf.layers.max_pooling2d(inputs=conv1,\n",
        "                                            pool_size=self.pollSize1,\n",
        "                                            strides=1,\n",
        "                                            name='pool1')\n",
        "            self.pool1 = pool1\n",
        "\n",
        "            conv2 = tf.layers.conv2d(inputs=pool1,\n",
        "                                     filters=self.numFeature2,\n",
        "                                     kernel_size=self.kernelSize2,\n",
        "                                     kernel_initializer = tf.contrib.layers.variance_scaling_initializer(factor=2.0, mode='FAN_IN', uniform=False),\n",
        "                                     padding=\"same\",\n",
        "                                     activation=selu.selu,\n",
        "                                     name='conv2')\n",
        "            self.conv2 = conv2\n",
        "\n",
        "            pool2 = tf.layers.max_pooling2d(inputs=conv2,\n",
        "                                            pool_size=self.pollSize2,\n",
        "                                            strides=1,\n",
        "                                            name='pool2')\n",
        "            self.pool2 = pool2\n",
        "\n",
        "            conv3 = tf.layers.conv2d(inputs=pool2,\n",
        "                                     filters=self.numFeature3,\n",
        "                                     kernel_size=self.kernelSize3,\n",
        "                                     kernel_initializer = tf.contrib.layers.variance_scaling_initializer(factor=2.0, mode='FAN_IN', uniform=False),\n",
        "                                     padding=\"same\",\n",
        "                                     activation=selu.selu,\n",
        "                                     name='conv3')\n",
        "            self.conv3 = conv3\n",
        "\n",
        "            pool3 = tf.layers.max_pooling2d(inputs=conv3,\n",
        "                                            pool_size=self.pollSize3,\n",
        "                                            strides=1,\n",
        "                                            name='pool3')\n",
        "            self.pool3 = pool3\n",
        "\n",
        "            flat_size = ( self.inputShape[0] - (self.pollSize1[0] - 1) - (self.pollSize2[0] - 1) - (self.pollSize3[0] - 1))\n",
        "            flat_size *= ( self.inputShape[1] - (self.pollSize1[1] - 1) - (self.pollSize2[1] - 1) - (self.pollSize3[1] - 1))\n",
        "            flat_size *= self.numFeature3\n",
        "            conv3_flat =  tf.reshape(pool3, [-1,  flat_size])\n",
        "\n",
        "            fc4 = tf.layers.dense(inputs=conv3_flat,\n",
        "                                 units=self.hiddenLayerUnits4,\n",
        "                                 kernel_initializer = tf.contrib.layers.variance_scaling_initializer(factor=2.0, mode='FAN_IN', uniform=False),\n",
        "                                 activation=selu.selu,\n",
        "                                 name='fc4')\n",
        "            self.fc4 = fc4\n",
        "\n",
        "            dropout4 = selu.dropout_selu(fc4, dropoutRateFC4PH, training=phasePH, name='dropout4')\n",
        "            self.dropout4 = dropout4\n",
        "\n",
        "            fc5 = tf.layers.dense(inputs=dropout4,\n",
        "                                 units=self.hiddenLayerUnits5,\n",
        "                                 kernel_initializer = tf.contrib.layers.variance_scaling_initializer(factor=2.0, mode='FAN_IN', uniform=False),\n",
        "                                 activation=selu.selu,\n",
        "                                 name='fc5')\n",
        "            self.fc5 = fc5\n",
        "\n",
        "            dropout5 = selu.dropout_selu(fc5, dropoutRateFC5PH, training=phasePH, name='dropout5')\n",
        "            self.dropout5 = dropout5\n",
        "\n",
        "            epsilon = tf.constant(value=1e-10)\n",
        "            YBaseChangeSigmoid = tf.layers.dense(inputs=dropout4, units=self.outputShape1[0], activation=tf.nn.sigmoid, name='YBaseChangeSigmoid')\n",
        "            self.YBaseChangeSigmoid = YBaseChangeSigmoid\n",
        "            YZygosityFC = tf.layers.dense(inputs=dropout5, units=self.outputShape2[0], activation=selu.selu, name='YZygosityFC')\n",
        "            YZygosityLogits = tf.add(YZygosityFC, epsilon, name='YZygosityLogits')\n",
        "            YZygositySoftmax = tf.nn.softmax(YZygosityLogits, name='YZygositySoftmax')\n",
        "            self.YZygositySoftmax = YZygositySoftmax\n",
        "            YVarTypeFC = tf.layers.dense(inputs=dropout5, units=self.outputShape3[0], activation=selu.selu, name='YVarTypeFC')\n",
        "            YVarTypeLogits = tf.add(YVarTypeFC, epsilon, name='YVarTypeLogits')\n",
        "            YVarTypeSoftmax = tf.nn.softmax(YVarTypeLogits, name='YVarTypeSoftmax')\n",
        "            self.YVarTypeSoftmax = YVarTypeSoftmax\n",
        "            YIndelLengthFC = tf.layers.dense(inputs=dropout5, units=self.outputShape4[0], activation=selu.selu, name='YIndelLengthFC')\n",
        "            YIndelLengthLogits = tf.add(YIndelLengthFC, epsilon, name='YIndelLengthLogits')\n",
        "            YIndelLengthSoftmax = tf.nn.softmax(YIndelLengthLogits, name='YIndelLengthSoftmax')\n",
        "            self.YIndelLengthSoftmax = YIndelLengthSoftmax\n",
        "\n",
        "            loss1 = tf.reduce_sum(tf.pow(YBaseChangeSigmoid - tf.slice(YPH,[0,0],[-1,self.outputShape1[0]], name='YBaseChangeGetTruth'), 2, name='YBaseChangeMSE'), name='YBaseChangeReduceSum')\n",
        "            YZygosityCrossEntropy = tf.nn.log_softmax(YZygosityLogits, name='YZygosityLogSoftmax')\\\n",
        "                                    * -tf.slice(YPH, [0,self.outputShape1[0]], [-1,self.outputShape2[0]], name='YZygosityGetTruth')\n",
        "            loss2 = tf.reduce_sum(YZygosityCrossEntropy, name='YZygosityReduceSum')\n",
        "            YVarTypeCrossEntropy = tf.nn.log_softmax(YVarTypeLogits, name='YVarTypeLogSoftmax')\\\n",
        "                                   * -tf.slice(YPH, [0,self.outputShape1[0]+self.outputShape2[0]], [-1,self.outputShape3[0]], name='YVarTypeGetTruth')\n",
        "            loss3 = tf.reduce_sum(YVarTypeCrossEntropy, name='YVarTypeReduceSum')\n",
        "            YIndelLengthCrossEntropy = tf.nn.log_softmax(YIndelLengthLogits, name='YIndelLengthLogSoftmax')\\\n",
        "                                       * -tf.slice(YPH, [0,self.outputShape1[0]+self.outputShape2[0]+self.outputShape3[0]], [-1,self.outputShape4[0]], name='YIndelLengthGetTruth')\n",
        "            loss4 = tf.reduce_sum(YIndelLengthCrossEntropy, name='YIndelLengthReduceSum')\n",
        "            lossL2 = tf.add_n([ tf.nn.l2_loss(v) for v in tf.trainable_variables() if 'bias' not in v.name ]) * l2RegularizationLambdaPH\n",
        "            loss = loss1 + loss2 + loss3 + loss4 + lossL2\n",
        "            self.loss = loss\n",
        "\n",
        "            # add tensorboard embedding\n",
        "            self.embedding1 = YBaseChangeSigmoid\n",
        "            self.embedding2 = YZygosityLogits\n",
        "            self.embedding3 = YVarTypeLogits\n",
        "            self.embedding4 = YIndelLengthLogits\n",
        "            # add summaries\n",
        "            tf.summary.scalar('learning_rate', learningRatePH)\n",
        "            tf.summary.scalar('l2Lambda', l2RegularizationLambdaPH)\n",
        "            tf.summary.scalar(\"loss1\", loss1)\n",
        "            tf.summary.scalar(\"loss2\", loss2)\n",
        "            tf.summary.scalar(\"loss3\", loss3)\n",
        "            tf.summary.scalar(\"loss4\", loss4)\n",
        "            tf.summary.scalar(\"lossL2\", lossL2)\n",
        "            tf.summary.scalar(\"loss\", loss)\n",
        "\n",
        "            # For report or debug. Fetching histogram summary is slow, GPU utilization will be low if enabled.\n",
        "            #for var in tf.trainable_variables():\n",
        "            #    tf.summary.histogram(var.op.name, var)\n",
        "            self.merged_summary_op = tf.summary.merge_all()\n",
        "\n",
        "            self.training_op = tf.train.AdamOptimizer(learning_rate=learningRatePH).minimize(loss)\n",
        "            self.init_op = tf.global_variables_initializer()\n",
        "\n",
        "    def init(self):\n",
        "        self.session.run( self.init_op )\n",
        "\n",
        "    def close(self):\n",
        "        self.session.close()\n",
        "\n",
        "    def train(self, batchX, batchY):\n",
        "        #for i in range(len(batchX)):\n",
        "        #    tf.image.per_image_standardization(batchX[i])\n",
        "        loss, _, summary = self.session.run( (self.loss, self.training_op, self.merged_summary_op),\n",
        "                                              feed_dict={self.XPH:batchX, self.YPH:batchY,\n",
        "                                                         self.learningRatePH:self.learningRateVal,\n",
        "                                                         self.phasePH:True,\n",
        "                                                         self.dropoutRateFC4PH:self.dropoutRateFC4Val,\n",
        "                                                         self.dropoutRateFC5PH:self.dropoutRateFC5Val,\n",
        "                                                         self.l2RegularizationLambdaPH:self.l2RegularizationLambdaVal})\n",
        "        return loss, summary\n",
        "\n",
        "    def trainNoRT(self, batchX, batchY):\n",
        "        #for i in range(len(batchX)):\n",
        "        #    tf.image.per_image_standardization(batchX[i])\n",
        "        self.trainLossRTVal = None; self.trainSummaryRTVal = None\n",
        "        self.trainLossRTVal, _, self.trainSummaryRTVal = self.session.run( (self.loss, self.training_op, self.merged_summary_op),\n",
        "                                              feed_dict={self.XPH:batchX, self.YPH:batchY,\n",
        "                                                         self.learningRatePH:self.learningRateVal,\n",
        "                                                         self.phasePH:True,\n",
        "                                                         self.dropoutRateFC4PH:self.dropoutRateFC4Val,\n",
        "                                                         self.dropoutRateFC5PH:self.dropoutRateFC5Val,\n",
        "                                                         self.l2RegularizationLambdaPH:self.l2RegularizationLambdaVal})\n",
        "\n",
        "    def getLoss(self, batchX, batchY):\n",
        "        #for i in range(len(batchX)):\n",
        "        #    tf.image.per_image_standardization(batchX[i])\n",
        "        loss = self.session.run( self.loss, feed_dict={self.XPH:batchX, self.YPH:batchY,\n",
        "                                                       self.learningRatePH:0.0,\n",
        "                                                       self.phasePH:False,\n",
        "                                                       self.dropoutRateFC4PH:0.0,\n",
        "                                                       self.dropoutRateFC5PH:0.0,\n",
        "                                                       self.l2RegularizationLambdaPH:0.0})\n",
        "        return loss\n",
        "\n",
        "    def getLossNoRT(self, batchX, batchY):\n",
        "        #for i in range(len(batchX)):\n",
        "        #    tf.image.per_image_standardization(batchX[i])\n",
        "        self.getLossLossRTVal = None\n",
        "        self.getLossLossRTVal = self.session.run( self.loss, feed_dict={self.XPH:batchX, self.YPH:batchY,\n",
        "                                                                        self.learningRatePH:0.0,\n",
        "                                                                        self.phasePH:False,\n",
        "                                                                        self.dropoutRateFC4PH:0.0,\n",
        "                                                                        self.dropoutRateFC5PH:0.0,\n",
        "                                                                        self.l2RegularizationLambdaPH:0.0})\n",
        "\n",
        "    def setLearningRate(self, learningRate=None):\n",
        "        if learningRate == None:\n",
        "            self.learningRateVal = self.learningRateVal * self.learningRateDecay\n",
        "        else:\n",
        "            self.learningRateVal = learningRate\n",
        "        return self.learningRateVal\n",
        "\n",
        "    def setL2RegularizationLambda(self, l2RegularizationLambda=None):\n",
        "        if  l2RegularizationLambda == None:\n",
        "            self.l2RegularizationLambdaVal = self.l2RegularizationLambdaVal * self.l2RegularizationLambdaDecay\n",
        "        else:\n",
        "            self.l2RegularizationLambdaVal = l2RegularizationLambda\n",
        "        return self.l2RegularizationLambdaVal\n",
        "\n",
        "    def saveParameters(self, fn):\n",
        "        with self.g.as_default():\n",
        "            self.saver = tf.train.Saver()\n",
        "            self.saver.save(self.session, fn)\n",
        "\n",
        "    def restoreParameters(self, fn):\n",
        "        with self.g.as_default():\n",
        "            self.saver = tf.train.Saver()\n",
        "            self.saver.restore(self.session, fn)\n",
        "\n",
        "    def summaryFileWriter(self, logsPath):\n",
        "        summaryWriter = tf.summary.FileWriter(logsPath, graph=self.g)\n",
        "        return summaryWriter\n",
        "\n",
        "    def predict(self, XArray):\n",
        "        #for i in range(len(batchX)):\n",
        "        #    tf.image.per_image_standardization(XArray[i])\n",
        "        base, zygosity, varType, indelLength = self.session.run( (self.YBaseChangeSigmoid, self.YZygositySoftmax, self.YVarTypeSoftmax, self.YIndelLengthSoftmax),\n",
        "                                                                  feed_dict={self.XPH:XArray,\n",
        "                                                                             self.learningRatePH:0.0,\n",
        "                                                                             self.phasePH:False,\n",
        "                                                                             self.dropoutRateFC4PH:0.0,\n",
        "                                                                             self.dropoutRateFC5PH:0.0,\n",
        "                                                                             self.l2RegularizationLambdaPH:0.0})\n",
        "        return base, zygosity, varType, indelLength\n",
        "\n",
        "    def predictNoRT(self, XArray):\n",
        "        #for i in range(len(batchX)):\n",
        "        #    tf.image.per_image_standardization(XArray[i])\n",
        "        self.predictBaseRTVal = None; self.predictZygosityRTVal = None; self.predictVarTypeRTVal = None; self.predictIndelLengthRTVal = None\n",
        "        self.predictBaseRTVal, self.predictZygosityRTVal, self.predictVarTypeRTVal, self.predictIndelLengthRTVal \\\n",
        "                                             = self.session.run( (self.YBaseChangeSigmoid, self.YZygositySoftmax, self.YVarTypeSoftmax, self.YIndelLengthSoftmax),\n",
        "                                                                  feed_dict={self.XPH:XArray,\n",
        "                                                                             self.learningRatePH:0.0,\n",
        "                                                                             self.phasePH:False,\n",
        "                                                                             self.dropoutRateFC4PH:0.0,\n",
        "                                                                             self.dropoutRateFC5PH:0.0,\n",
        "                                                                             self.l2RegularizationLambdaPH:0.0})\n",
        "\n",
        "    def __del__(self):\n",
        "        self.session.close()"
      ],
      "metadata": {
        "id": "RSgWzFgSP4CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Params"
      ],
      "metadata": {
        "id": "IipruHm9Q7gF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_THREADS = 2\n",
        "\n",
        "flankingBaseNum = 16        \n",
        "matrixNum = 4               \n",
        "bloscBlockSize = 500\n",
        "\n",
        "# Model hyperparameters\n",
        "predictBatchSize = 2000\n",
        "initialLearningRate = 0.001\n",
        "learningRateDecay = 0.1\n",
        "\n",
        "l2RegularizationLambda = 0.001\n",
        "l2RegularizationLambdaDecay = 0.1\n",
        "dropoutRateFC4 = 0.5\n",
        "dropoutRateFC5 = 0.0\n",
        "\n",
        "def str2bool(v):\n",
        "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "        return True\n",
        "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
        "        return False\n",
        "    else:\n",
        "        import sys\n",
        "        raise sys.exit('Boolean value expected.')"
      ],
      "metadata": {
        "id": "xI3_ugQ7Q-Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaled ELU function and Dropout"
      ],
      "metadata": {
        "id": "wY2K_Xz4RNIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import numbers\n",
        "from tensorflow.contrib import layers\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.framework import tensor_shape\n",
        "from tensorflow.python.framework import tensor_util\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops import random_ops\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.contrib.layers.python.layers import utils\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "def selu(x):\n",
        "    with ops.name_scope('elu') as scope:\n",
        "        alpha = 1.6732632423543772848170429916717\n",
        "        scale = 1.0507009873554804934193349852946\n",
        "        return scale*tf.where(x>=0.0, x, alpha*tf.nn.elu(x))\n",
        "\n",
        "\n",
        "initializer = layers.variance_scaling_initializer(factor=1.0, mode='FAN_IN')\n",
        "\n",
        "\n",
        "def dropout_selu(x, rate, alpha= -1.7580993408473766, fixedPointMean=0.0, fixedPointVar=1.0,\n",
        "                 noise_shape=None, seed=None, name=None, training=False):\n",
        "    \"\"\"Dropout to a value with rescaling.\"\"\"\n",
        "\n",
        "    def dropout_selu_impl(x, rate, alpha, noise_shape, seed, name):\n",
        "        keep_prob = 1.0 - rate\n",
        "        x = ops.convert_to_tensor(x, name=\"x\")\n",
        "        if isinstance(keep_prob, numbers.Real) and not 0 < keep_prob <= 1:\n",
        "            raise ValueError(\"keep_prob must be a scalar tensor or a float in the \"\n",
        "                                             \"range (0, 1], got %g\" % keep_prob)\n",
        "        keep_prob = ops.convert_to_tensor(keep_prob, dtype=x.dtype, name=\"keep_prob\")\n",
        "        keep_prob.get_shape().assert_is_compatible_with(tensor_shape.scalar())\n",
        "\n",
        "        alpha = ops.convert_to_tensor(alpha, dtype=x.dtype, name=\"alpha\")\n",
        "        alpha.get_shape().assert_is_compatible_with(tensor_shape.scalar())\n",
        "\n",
        "        if tensor_util.constant_value(keep_prob) == 1:\n",
        "            return x\n",
        "\n",
        "        noise_shape = noise_shape if noise_shape is not None else array_ops.shape(x)\n",
        "        random_tensor = keep_prob\n",
        "        random_tensor += random_ops.random_uniform(noise_shape, seed=seed, dtype=x.dtype)\n",
        "        binary_tensor = math_ops.floor(random_tensor)\n",
        "        ret = x * binary_tensor + alpha * (1-binary_tensor)\n",
        "\n",
        "        a = math_ops.sqrt(fixedPointVar / (keep_prob *((1-keep_prob) * math_ops.pow(alpha-fixedPointMean,2) + fixedPointVar)))\n",
        "\n",
        "        b = fixedPointMean - a * (keep_prob * fixedPointMean + (1 - keep_prob) * alpha)\n",
        "        ret = a * ret + b\n",
        "        ret.set_shape(x.get_shape())\n",
        "        return ret\n",
        "\n",
        "    with ops.name_scope(name, \"dropout\", [x]) as name:\n",
        "        return utils.smart_cond(training,\n",
        "            lambda: dropout_selu_impl(x, rate, alpha, noise_shape, seed, name),\n",
        "            lambda: array_ops.identity(x))"
      ],
      "metadata": {
        "id": "_uiKuPlhRNzb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}